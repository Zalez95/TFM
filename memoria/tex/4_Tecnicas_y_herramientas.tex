\capitulo{4}{Técnicas y herramientas}

Este apartado tiene el objetivo de enumerar y describir las múltiples herramientas utilizadas para el desarrollo del presente proyecto.

Durante la fase inicial se trató de llevar a cabo una prueba de concepto empleando el lenguaje de programación Python para comprobar la viabilidad de la idea y la dificultad de implementación de descarga de datos y el posterior proceso de análisis de sentimientos. La decisión de usar este lenguaje de programación se basa en que es un lenguaje que conozco ya que he trabajado con éste en el pasado, y que considero sencillo y especialmente útil para llevar a cabo prototipos de forma rápida, ya que al ser muy popular actualmente, es muy fácil encontrar librerías y recursos en la web en caso de duda.

\section{Instalooter}

El primer paso que se llevo a cabo para esta prueba de concepto fue investigar las posibles herramientas para llevar a cabo la descarga de datos de la página web de Instagram. Tras hacer varias pruebas con múltiples scrapers web encontrados en GitHub se decidió emplear Instalooter, el cual dispone tanto de una interfaz de programación para Python como de un cliente de línea de comandos. El resto de scrapers encontrados no parecían funcionar, posiblemente porque la web de Instagram haya sido actualizada recientemente y éstos programas no hayan sido actualizados de acorde a estos cambios en el momento en que hice la prueba. La API de Instalooter pone a disposición del usuario de varios \textit{looters} ya sea para descargar las publicaciones llevadas a cabo por un usuario en su perfil o para descargar publicaciones relacionadas con un Hashtag, y permite descargar tanto las imágenes como la descripción y metadatos de las mismas en formato JSON. Además, antes de descargar la información de una publicación Instalooter comprueba que no haya sido ya descargada, con lo que puede ejecutarse repetidamente sobre un perfil o un Hashtag sin peligro de obtener resultados duplicados.

\section{Servicios en la Nube}

Respecto al almacenamiento y procesado de los datos descargados de las publicaciones de Instagram, se trató desde un principio de usar computación en la nube debido a la facilidad de uso y de escalado de la capacidad de almacenamiento y computación en caso de que fuese necesario.

Inicialmente por recomendación del tutor se trató de emplear los servicios de Google Cloud. Esta plataforma de Google Cloud provee diversos servicios junto con sus respectivas interfaces de programación compatibles con múltiples lenguajes de programación. Entre los servicios relevantes para el presente proyecto cabe destacar el almacenamiento en la nube con Cloud Storage, servicios de procesamiento de datos y creación de máquinas virtuales con Compute Engine, servicios de visión artificial mediante Cloud Vision, almacenamiento de bases de datos en Cloud SQL, etc. Todos estos servicios se pueden probar de forma gratuita con tan solo crearse una cuenta en la plataforma. Esto es debido a que Google ofrece 300 USD para invertir libremente a toda cuenta recién creada durante un periodo de 3 meses, 400 USD si se demuestra que eres alumno \cite{google_cloud}. Este crédito inicial se va gastando según se vaya haciendo uso de los servicios, y una vez consumido o pasado el periodo de 3 meses, Google empieza a cobrar por el uso de sus servicios. Debido al alcance de este proyecto y los precios que tienen los servicios de Google, el límite de dinero no parece preocupante, aunque el de tiempo si que puede llegar a serlo.

Como se ha comentado con anterioridad, para emplear los servicios de Google Cloud, Google pone a disposición de los usuarios APIs de forma gratuita para distintos lenguajes de programación, entre los cuales se encuentra Python. Mediante este lenguaje de scripting y la API de Cloud Vision \cite{api_google_vision}, se llevaron a cabo unas pruebas iniciales donde se pudo comprobar que la información que se puede obtener mediante el uso de la API de Google Cloud Vision si que incluye cierta capacidad de análisis de emociones, permitiendo obtener etiquetas de emociones como alegría, tristeza, enfado, sorpresa, etc. junto con su \textit{likelihood}, pero no incluye información como edad y género de las personas, capacidad que fue eliminada de este servicio de forma bastante reciente  \cite{archive_google_gender}. Esto es un problema ya que se pretendía hacer uso de este tipo de información a la hora de recomendar publicaciones o lugares al usuario. Debido a esto se decidió comparar las alternativas existentes a estos servicios en la nube de Google.

A continuación se hace un pequeño resumen de los servicios ofrecidos por las alternativas valoradas y que posiblemente se puedan llegar a necesitar en el proyecto. Cabe destacar que se seleccionaron solo estas alternativas en base a los servicios necesarios y al requerimiento de que la plataforma usada fuera gratuita u ofreciese un periodo de prueba, ya sea para estudiantes o no, lo suficientemente extenso como para poder desarrollar el proyecto sin complicaciones.

\begin{landscape}
\begin{table}[]
    \centering
    \resizebox{1.02\columnwidth}{0.55\textwidth}{%
        \begin{tabular}{|p{0.12\textwidth}|p{0.2\textwidth}|p{0.15\textwidth}|p{0.15\textwidth}|p{0.15\textwidth}|p{0.21\textwidth}|p{0.21\textwidth}|p{0.21\textwidth}|p{0.21\textwidth}|}
        \hline
        \multirow{2}{=}{Servicios} & \multirow{2}{=}{Límite de uso}	& \multicolumn{3}{|c|}{API de Visión Artificial}	& \multirow{2}{=}{Almacenamiento en bucket/blobs gratuito}	& \multirow{2}{=}{Almacenamiento en Base de Datos SQL}	& \multirow{2}{=}{Almacenamiento en Base de Datos NoSQL}	& \multirow{2}{=}{Máquinas Virtuales}	\\ \cline{3-5}
        	&	& Límite de uso	& Análisis de Sentimiento	& Reconoci\-miento de edad y género &	&	&	&	\\ \hline
        Google Cloud	& 300 USD durante 3 meses	& 1000 unidades al mes	& Si, con tags alegría, tristeza, enojo, sorpresa	& No	& Si, con 5 Gbs al mes en Google Cloud Storage	& Si, con motor de base de datos MySQL, PostgreSQL y SQL Server	& Si, bases de datos documentales como Cloud Datastore, Cloud Firestore... y clave/valor con MongoDB, Bigtable...	& Si, Máquina virtual en Compute Engine empleando el saldo inicial	\\ \hline
        Microsoft Azure	& 12 meses para servicios gratuitos + 200 USD para servicios no gratuitos durante 1 mes & Hasta 30.000 transacciones al mes & Si, con tags felicidad, tristeza, neutralidad, ira, desprecio, asco, sorpresa y temor	& Si	& Si, con 5 Gbs en Azure Blob Storage y 5 GBs en Azure File Storage 5 & Si, con Azure Database for MySQL (750 horas al mes), Azure Database for PostgreSQL (750 horas al mes) y SQL Database (250 Gbs)	& Si, Azure Cosmos DB (25 Gbs)	& Si, Máquina virtual B1S (1 núcleo, 1 GB RAM y 4GB de almacenamiento) con Linux 750 horas al mes	\\ \hline
        Amazon Web Services (AWS)	& 12 meses para la capa gratuita	& 5000 imágenes al mes	& Si, con tags feliz, triste, enfado, confuso, disgustado, sorprendido, calma, miedo, desconocido & Si	& Si, con 5 Gbs al mes en Amazon S3	& Si, se puede usar RDS (750 horas al mes) con motor de base de datos MySQL, MariaDB, Oracle, PostgreSQL, SQL Server y Amazon Aurora & Si, bases de datos documentales con DocumentDB (compatible con MongoDB, solo 1 mes de prueba) y clave/valor con DynamoDB (25 GB gratuitos) & Si, Máquina virtual en EC2 (1 CPU, 1GB de RAM, 1 CPU y 1GB de RAM, 30 GBs SSD) con Linux 750 horas al mes \\ \hline
        \end{tabular}%
    }
    \caption{Servicios en la Nube: Alternativas}
    \label{tab:cloud_services}
\end{table}
\end{landscape}

Hay que destacar que se intentó llevar a cabo pruebas en las distintas plataformas mediante sus respectivas interfaces de programación. Durante las pruebas, con los servicios de Microsoft Azure no se consiguió llegar a crear una máquina virtual de tipo \texttt{B1S} gratuita, siempre salían como no disponibles. Tras revisar la página de preguntas y respuestas de Microsoft parece que a mucha gente le ha sucedido lo mismo, el problema parece ser la alta demanda de este tipo de máquinas. Debido a este problema y la imposibilidad de obtener la edad y el genero en los servicios de Google Vision, se decidió que lo mejor era emplear los servicios de \textbf{Amazon Web Services}.

\subsection{Amazon S3}
Amazon S3, \textit{Simple Storage Service} por sus siglas en inglés, es un servicio de almacenamiento de objetos en la nube de Amazon. El almacenamiento en S3 permite almacenar cualquier tipo de objeto de forma escalable, con baja latencia y alta disponibilidad. El acceso a este servicio puede llevarse a cabo mediante la consola web de Amazon AWS, el SDK de AWS o mediante APIs REST.

Cada objeto almacenado en S3 se ubica dentro de un recurso denominado ``bucket'' y puede llegar a ocupar hasta 5TBs \cite{amazon_s3}. Estos objetos se organizan mediante prefijos y se les puede añadir hasta 10 etiquetas clave-valor. Además, se puede habilitar que la modificación de los objetos almacenados en S3 pueda ser supervisada mediante sistemas de control de versiones así como habilitar Multi-Factor Athentication para evitar el borrado accidental. Cabe destacar también que los objetos pueden ser replicados en varias regiones para reducir la latencia de acceso si nuestra aplicacion así lo requiere.

Amazon S3 tiene varias clases de almacenaniento. Dependiendo del caso de uso y la forma en que se va a acceder a los datos puede ser más conveniente usar una clase u otra con el fin de reducir la latencia y el coste de servicio de nuestra aplicación. Estas clases son las siguientes:
\begin{itemize}
    \item \textit{S3 Intelligent-Tiering}: preferible para aplicaciones con patrones de acceso desconocidos o cambiantes ya que optimiza de forma automática los costes de almacenamiento.
    \item \textit{S3 Standard}: preferible para los datos de acceso frecuente.
    \item \textit{S3 Standard-Infrequent Access} y \textit{S3 One Zone-Infrequent Access}: preferibles para los datos de acceso poco frecuente.
    \item \textit{S3 Glacier Instant Retrieval}, \textit{S3 Glacier Flexible Retrieval} y \textit{S3 Glacier Deep Archive}: preferibles para el archivado de datos, siendo preferible uno u otro en base a las necesidades de tiempo de recuperación (\textit{instant} en milisegundos, \textit{flexible} en minutos, \textit{deep archive} en horas).
    \item \textit{S3 Outposts}: útil para aquellos casos donde existe alguna normativa que nos obliga a mantener los datos fuera de alguna región en concreto.
\end{itemize}

Además Amazon S3 permite regular el acceso a los datos mediante listas de control de acceso (ACL), políticas de bucket, etc. Cabe destacar que el servicio IAM de AWS simplifica mucho la administración del acceso a los datos.

\subsection{Amazon EC2}

Amazon EC2, Elastic Compute Cloud por sus siglas en inglés, 

\subsection{DynamoDB}

\section{Grafana}

Grafana es una herramienta multiplataforma de código abierto para la visualización y análisis de datos. Para ello Grafana permite crear, explorar y compartir cuadros de mando \cite{wiki_grafana}\cite{github_grafana}. Entre las múltiples características que ofrece esta herramienta cabe destacar:

\begin{itemize}
    \item Es una herramienta flexible que permite crear diversos tipos de gráficos con multitud de opciones, como histogramas, mapas geográficos, gráficos de tarta, de barras, etc.
    \item Permite la creación de dashboard dinámicos que pueden ser reusados fácilmente. Los cuadros de mando se pueden exportar en formato JSON de forma que se puede copiar y pegar de una forma sencilla.
    \item Se pueden añadir variables que pueden ser usadas como filtros.
    \item Permite la creación de consultas de forma dinámica y comparar diferentes rangos de tiempo.
    \item Puede ser usado para explorar logs en vivo.
    \item Permite definir alertas en base a distintas métricas.
    \item Es capaz de mezclar datos de distintos orígenes en un mismo dashboard.
\end{itemize}

Grafana es extensible mediante plugins que permiten añadir funcionalidad así como conectores con distintos tipos de fuentes de datos. Al ser código abierto existe una gran comunidad detrás de Grafana que ayuda tanto al desarrollo y soporte de la herramienta en sí, como para la creación de nuevos plugins. En la actualidad hay conectores para múltiples fuentes de datos como pueden ser hojas de cálculo, bases de datos MySQL, Oracle, MongoDB, Splunk...

\section{Otras herramientas}

Además de las anteriores herramientas utilizadas para la descarga, almacenamiento y procesamiento de datos, se han utilizados otras herramientas y utilidades para llevar a cabo tanto la implementación de los programas como la realización de la memoria, entre las que cabe destacar:

\begin{itemize}
    \item virtualenv: herramienta empleada en Python para crear entornos aislados, evitando que las actualizaciones e instalaciones llevadas a cabo para otros proyectos afecten al actual.
    \item Visual Studio Code: editor de código fuente usado para la implementación de los scripts.
    \item Git: Sistema de Control de Versiones empleado tanto con el código como con la memoria del proyecto. El repositorio se decidió almacenar en la forja GitHub para poder compartirlo fácilmente con el tutor, y además para poder acceder a sus herramientas de seguimiento del proyecto.
    \item \LaTeX: Sistema de composición de textos de alta calidad empleado para la creación de la memoria. LaTeX se usó junto con la web Overleaf, ya que ésta evita tener que instalar todo el entorno de compilación de LaTeX junto con sus dependencias, y además permite sincronizar los cambios con GitHub fácilmente.
\end{itemize}
